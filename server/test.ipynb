{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将当前目录添加到 PYTHONPATH\n",
    "import sys\n",
    "import os\n",
    "\n",
    "cwd = os.path.dirname(os.path.abspath(\"./server\"))\n",
    "sys.path.append(cwd)\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from client import MCPClient, MCPClientConfig, LLMConfig, MCPServerConfig\n",
    "from openai_adapter import OpenAIAdapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = MCPClientConfig(\n",
    "    mcp_servers=[\n",
    "        MCPServerConfig(\n",
    "            name=\"music_player\",\n",
    "            transport=\"sse\",\n",
    "            url=\"http://localhost:8000/sse\"\n",
    "        )\n",
    "    ],\n",
    "    llm=LLMConfig(  \n",
    "        provider=\"ollama\",\n",
    "        api_key=\"ollama\",\n",
    "        base_url=\"http://localhost:11434/v1\",\n",
    "        sys_prompt=\"你是一个经验丰富的助手\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MCPClient(config)\n",
    "await client.connect_to_servers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await client.process_query(\"qwen2.5:latest\", \"你好\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async for chunk in client.stream_process_query(\"qwen2.5:latest\", \"你好\"):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async for chunk in client.stream_process_query(\"qwen2.5:latest\", \"你好, 帮我随便放首歌，最好的比较舒缓放松的那种\"):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_adapter = OpenAIAdapter(\n",
    "    provider=\"ollama\",\n",
    "    api_key=\"ollama\",\n",
    "    base_url=\"http://localhost:11434/v1\",\n",
    ")\n",
    "\n",
    "tools, _ = await client.list_all_tools()\n",
    "print(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = await llm_adapter.chat(\n",
    "    model=\"qwen3:latest\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"你好, 帮我随便放首歌，最好的比较舒缓放松的那种\"}\n",
    "    ],\n",
    "    tools=tools,\n",
    "    stream=True\n",
    ")\n",
    "async for chunk in resp:\n",
    "    print(chunk)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "found invalid characters: {'1'}\n",
      "found invalid characters: {'2'}\n",
      "text:   3%|▎         | 10/384(max) [00:01,  5.35it/s]\n",
      "code:   3%|▎         | 62/2048(max) [00:06,  9.93it/s]\n"
     ]
    }
   ],
   "source": [
    "import ChatTTS\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "chat = ChatTTS.Chat()\n",
    "chat.load(compile=False) # Set to True for better performance\n",
    "\n",
    "texts = [\"你好，我是小爱同学，很高兴认识你\"]\n",
    "\n",
    "wavs = chat.infer(texts)\n",
    "\n",
    "for i in range(len(wavs)):\n",
    "    torchaudio.save(f\"basic_output{i}.wav\", torch.from_numpy(wavs[i]).unsqueeze(0), 24000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
